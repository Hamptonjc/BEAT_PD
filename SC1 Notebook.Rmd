---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.4.1
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# BEAT-PD SC1 Subject Specific Models Notebook

```{python}
# Imports
import os
import sys
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline

import torch
import pytorch_lightning as pl
from pytorch_lightning.logging import TensorBoardLogger
from tensorboard import notebook
from argparse import Namespace
import torch.nn as nn
import torchvision as tv
import torchvision.transforms.functional as TF
from torch.nn import functional as F
from torchvision import transforms, models
from torch.utils import data
from torch.utils.data import DataLoader
from PIL import Image
import glob
import random
```

```{python}
# Run .py files
# %run -i Dataset_ensemble.py
# %run -i Torch_Dataset.py
# %run -i BEATPD_LSTM.py
# %run -i EvalUtilities.py
# %run -i LightningEnsemble.py
```

```{python}
torch.cuda.empty_cache()
```

# Identifying Sub Challenge 1 Test Subjects

```{python}
cis_tst_id = pd.read_csv('Data/BEATPDchallenge/CIS-PD_Test_Data_IDs.csv')
```

```{python}
real_tst_id = pd.read_csv('Data/BEATPDchallenge/REAL-PD_Test_Data_IDs.csv')
```

```{python}
tst_sc1 = pd.read_csv('Data/BEATPDchallenge/BEAT-PD_SC1_OnOff_Submission_Template.csv')
```

```{python}
tst_sc1['subject_id'] = np.nan
```

```{python}
for idx1, row1 in tst_sc1.iterrows():
    for idx2, row2 in pd.concat([cis_tst_id,real_tst_id]).reset_index(drop=True).iterrows():
        if row1.measurement_id == row2.measurement_id:
            tst_sc1.subject_id[idx1] = row2.subject_id
```

```{python}
 tst_sc1.subject_id.unique()
```

# Create CIS Dataset

```{python}
############### REAL config ###############

# dataset_name = 'REAL'
# label_class = 'on_off'
# sort_by = 'on_off'
# train_ts_dir = 'Data/BEATPDchallenge/BeatPDRealPDupdated/real-pd.training_data_updated/training_data/'
# train_label_dir = 'Data/BEATPDchallenge/data_labels-realpd/REAL-PD_Training_Data_IDs_Labels.csv'
# ancil_ts_dir = 'Data/BEATPDchallenge/BeatPDRealPDupdated/real-pd.ancillary_data_updated/ancillary_data/'
# ancil_label_dir = 'Data/BEATPDchallenge/data_labels-realpd/REAL-PD_Ancillary_Data_IDs_Labels.csv'
#test_ts_dir='Data/BEATPDchallenge/BeatPDRealPDupdated/real-pd.testing_data_updated/testing_data/'
#test_data_id_dir='Data/BEATPDchallenge/REAL-PD_Test_Data_IDs.csv
```

```{python}
############### CIS config ###############

dataset_name = 'CIS'
label_class = 'on_off'
sort_by = 'subject_id'
train_ts_dir = 'Data/BEATPDchallenge/training_data-cispd/'
train_label_dir = 'Data/BEATPDchallenge/data_labels-cispd/CIS-PD_Training_Data_IDs_Labels.csv'
ancil_ts_dir = 'Data/BEATPDchallenge/ancillary_data-cispd/'
ancil_label_dir = 'Data/BEATPDchallenge/data_labels-cispd/CIS-PD_Ancillary_Data_IDs_Labels.csv'
test_ts_dir='Data/BEATPDchallenge/testing_data-cispd/'
test_data_id_dir='Data/BEATPDchallenge/CIS-PD_Test_Data_IDs.csv'
```

```{python}
dataset = Dataset(dataset_name=dataset_name, sort_by=sort_by, label_class = label_class,
                           train_ts_dir=train_ts_dir, train_label_dir=train_label_dir,
                           ancil_ts_dir=ancil_ts_dir, ancil_label_dir=ancil_label_dir,
                           combine_ancil=False,test_ts_dir=test_ts_dir, test_data_id_dir=test_data_id_dir)
```

```{python}
dataset.data_dict.keys()
```

```{python}
dataset.test_data_dict.keys()
```

## Model's Settings

```{python}
model_name = "Ensemble_v1"
checkpoint_callback = False
early_stop_callback=True 
max_epochs=10
gpus=1
learning_rate = 0.0001
train_batch_size = 1  #issue with batch size > 1, concat output into final classifier is batch_size*10
val_batch_size = 1
```

# Subject 1004 Model

```{python}
subject_id = 1004
```

```{python}
dataset.run_preprocessing(specific_key_dataset=subject_id)
```

```{python}
dataset.run_test_preprocessing(specific_key_dataset=subject_id)
```

## Train Validation Split

```{python}
dataset.train_validation_split(val_proportion=0.2)
```

```{python}
print('Training size:',len(dataset.train_list))
print('Validation size:',len(dataset.val_list))
```

## Run Training/Validation

```{python}
# Hyperparameters
hparams = Namespace(**{'learning_rate':learning_rate, 'train_batch_size': train_batch_size,
                       'val_batch_size': val_batch_size})
```

```{python}
# Start tensorboard
notebook.start(f'--logdir lightning_logs --host localhost --port 1334')
```

```{python}
notebook.display(port=1334)
```

```{python}
# Run training/validation of model
model = LightningEnsemble(dataset_name=dataset_name,hparams=hparams,train_list=dataset.train_list,
                       val_list=dataset.val_list,label_class=label_class)
logger = TensorBoardLogger("lightning_logs", name=model_name, version=f'subject_{subject_id}_{label_class}')
trainer = pl.Trainer(early_stop_callback=early_stop_callback,
                     max_epochs=max_epochs, gpus=gpus, logger=logger,checkpoint_callback=False)
trainer.fit(model)
```

```{python}
# List tensorboard instances
#notebook.list()
```

```{python}
#tensorboard kill
# #!taskkill /pid 11468 /f
```

```{python}
#torch.cuda.empty_cache()
```

## Make Predictions

```{python}
# Predict and fill in submission template
for spec, id_, subject, ts in dataset.test_data_list:
    output = model([torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0),
                    torch.tensor(ts).type('torch.FloatTensor').view(ts.shape[0], -1)])
    prediction = output.argmax(dim=0, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

```{python}
# View predictions
tst_sc1.head()
```

```{python}
 tst_sc1.subject_id.unique()
```

# Subject 1006 Model

```{python}
torch.cuda.empty_cache()
```

```{python}
subject_id = 1006
```

```{python}
dataset.run_preprocessing(specific_key_dataset=subject_id)
```

```{python}
dataset.run_test_preprocessing(specific_key_dataset=subject_id)
```

## Train Validation Split

```{python}
dataset.train_validation_split(val_proportion=0.2)
```

```{python}
print('Training size:',len(dataset.train_list))
print('Validation size:',len(dataset.val_list))
```

## Run Training/Validation

```{python}
# Hyperparameters
hparams = Namespace(**{'learning_rate':learning_rate, 'train_batch_size': train_batch_size,
                       'val_batch_size': val_batch_size})
```

```{python}
# Run training/validation of model
model = LightningEnsemble(dataset_name=dataset_name,hparams=hparams,train_list=dataset.train_list,
                       val_list=dataset.val_list,label_class=label_class)
logger = TensorBoardLogger("lightning_logs", name=model_name, version=f'subject_{subject_id}_{label_class}')
trainer = pl.Trainer(early_stop_callback=early_stop_callback,
                     max_epochs=max_epochs, gpus=gpus, logger=logger,checkpoint_callback=False)
trainer.fit(model)
```

## Make Predictions

```{python}
# Predict and fill in submission template
for spec, id_, subject, ts in dataset.test_data_list:
    output = model([torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0),
                    torch.tensor(ts).type('torch.FloatTensor').view(ts.shape[0], -1)])
    prediction = output.argmax(dim=0, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

```{python}
 tst_sc1.subject_id.unique()
```

# Subject 1007 Model

```{python}
torch.cuda.empty_cache()
```

```{python}
subject_id = 1007
```

```{python}
dataset.run_preprocessing(specific_key_dataset=subject_id)
```

```{python}
dataset.run_test_preprocessing(specific_key_dataset=subject_id)
```

## Train Validation Split

```{python}
dataset.train_validation_split(val_proportion=0.2)
```

```{python}
print('Training size:',len(dataset.train_list))
print('Validation size:',len(dataset.val_list))
```

## Run Training/Validation

```{python}
# Hyperparameters
hparams = Namespace(**{'learning_rate':learning_rate, 'train_batch_size': train_batch_size,
                       'val_batch_size': val_batch_size})
```

```{python}
# Run training/validation of model
model = LightningEnsemble(dataset_name=dataset_name,hparams=hparams,train_list=dataset.train_list,
                       val_list=dataset.val_list,label_class=label_class)
logger = TensorBoardLogger("lightning_logs", name=model_name, version=f'subject_{subject_id}_{label_class}')
trainer = pl.Trainer(early_stop_callback=early_stop_callback,
                     max_epochs=max_epochs, gpus=gpus, logger=logger,checkpoint_callback=False)
trainer.fit(model)
```

## Make Predictions

```{python}
# Predict and fill in submission template
for spec, id_, subject, ts in dataset.test_data_list:
    output = model([torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0),
                    torch.tensor(ts).type('torch.FloatTensor').view(ts.shape[0], -1)])
    prediction = output.argmax(dim=0, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

```{python}
 tst_sc1.subject_id.unique()
```

# Subject 1019 Model

```{python}
torch.cuda.empty_cache()
```

```{python}
subject_id = 1019
```

```{python}
dataset.run_preprocessing(specific_key_dataset=subject_id)
```

```{python}
dataset.run_test_preprocessing(specific_key_dataset=subject_id)
```

## Train Validation Split

```{python}
dataset.train_validation_split(val_proportion=0.2)
```

```{python}
print('Training size:',len(dataset.train_list))
print('Validation size:',len(dataset.val_list))
```

## Run Training/Validation

```{python}
# Hyperparameters
hparams = Namespace(**{'learning_rate':learning_rate, 'train_batch_size': train_batch_size,
                       'val_batch_size': val_batch_size})
```

```{python}
# Run training/validation of model
model = LightningEnsemble(dataset_name=dataset_name,hparams=hparams,train_list=dataset.train_list,
                       val_list=dataset.val_list,label_class=label_class)
logger = TensorBoardLogger("lightning_logs", name=model_name, version=f'subject_{subject_id}_{label_class}')
trainer = pl.Trainer(early_stop_callback=early_stop_callback,
                     max_epochs=max_epochs, gpus=gpus, logger=logger,checkpoint_callback=False)
trainer.fit(model)
```

## Make Predictions

```{python}
# Predict and fill in submission template
for spec, id_, subject, ts in dataset.test_data_list:
    output = model([torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0),
                    torch.tensor(ts).type('torch.FloatTensor').view(ts.shape[0], -1)])
    prediction = output.argmax(dim=0, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

```{python}
 tst_sc1.subject_id.unique()
```

# Subject 1020 Model

```{python}
torch.cuda.empty_cache()
```

```{python}
subject_id = 1020
```

```{python}
dataset.run_preprocessing(specific_key_dataset=subject_id)
```

```{python}
dataset.run_test_preprocessing(specific_key_dataset=subject_id)
```

## Train Validation Split

```{python}
dataset.train_validation_split(val_proportion=0.2)
```

```{python}
print('Training size:',len(dataset.train_list))
print('Validation size:',len(dataset.val_list))
```

## Run Training/Validation

```{python}
# Hyperparameters
hparams = Namespace(**{'learning_rate':learning_rate, 'train_batch_size': train_batch_size,
                       'val_batch_size': val_batch_size})
```

```{python}
# Run training/validation of model
model = LightningEnsemble(dataset_name=dataset_name,hparams=hparams,train_list=dataset.train_list,
                       val_list=dataset.val_list,label_class=label_class)
logger = TensorBoardLogger("lightning_logs", name=model_name, version=f'subject_{subject_id}_{label_class}')
trainer = pl.Trainer(early_stop_callback=early_stop_callback,
                     max_epochs=max_epochs, gpus=gpus, logger=logger,checkpoint_callback=False)
trainer.fit(model)
```

## Make Predictions

```{python}
# Predict and fill in submission template
for spec, id_, subject, ts in dataset.test_data_list:
    output = model([torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0),
                    torch.tensor(ts).type('torch.FloatTensor').view(ts.shape[0], -1)])
    prediction = output.argmax(dim=0, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

```{python}
 tst_sc1.subject_id.unique()
```

# Subject 1023 Model

```{python}
torch.cuda.empty_cache()
```

```{python}
subject_id = 1023
```

```{python}
dataset.run_preprocessing(specific_key_dataset=subject_id)
```

```{python}
dataset.run_test_preprocessing(specific_key_dataset=subject_id)
```

## Train Validation Split

```{python}
dataset.train_validation_split(val_proportion=0.2)
```

```{python}
print('Training size:',len(dataset.train_list))
print('Validation size:',len(dataset.val_list))
```

## Run Training/Validation

```{python}
# Hyperparameters
hparams = Namespace(**{'learning_rate':learning_rate, 'train_batch_size': train_batch_size,
                       'val_batch_size': val_batch_size})
```

```{python}
# Run training/validation of model
model = LightningEnsemble(dataset_name=dataset_name,hparams=hparams,train_list=dataset.train_list,
                       val_list=dataset.val_list,label_class=label_class)
logger = TensorBoardLogger("lightning_logs", name=model_name, version=f'subject_{subject_id}_{label_class}')
trainer = pl.Trainer(early_stop_callback=early_stop_callback,
                     max_epochs=max_epochs, gpus=gpus, logger=logger,checkpoint_callback=False)
trainer.fit(model)
```

## Make Predictions

```{python}
# Predict and fill in submission template
for spec, id_, subject, ts in dataset.test_data_list:
    output = model([torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0),
                    torch.tensor(ts).type('torch.FloatTensor').view(ts.shape[0], -1)])
    prediction = output.argmax(dim=0, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

```{python}
 tst_sc1.subject_id.unique()
```

# Subject 1032 Model

```{python}
torch.cuda.empty_cache()
```

```{python}
subject_id = 1032
```

```{python}
dataset.run_preprocessing(specific_key_dataset=subject_id)
```

```{python}
dataset.run_test_preprocessing(specific_key_dataset=subject_id)
```

## Train Validation Split

```{python}
dataset.train_validation_split(val_proportion=0.2)
```

```{python}
print('Training size:',len(dataset.train_list))
print('Validation size:',len(dataset.val_list))
```

## Run Training/Validation

```{python}
# Hyperparameters
hparams = Namespace(**{'learning_rate':learning_rate, 'train_batch_size': train_batch_size,
                       'val_batch_size': val_batch_size})
```

```{python}
# Run training/validation of model
model = LightningEnsemble(dataset_name=dataset_name,hparams=hparams,train_list=dataset.train_list,
                       val_list=dataset.val_list,label_class=label_class)
logger = TensorBoardLogger("lightning_logs", name=model_name, version=f'subject_{subject_id}_{label_class}')
trainer = pl.Trainer(early_stop_callback=early_stop_callback,
                     max_epochs=max_epochs, gpus=gpus, logger=logger,checkpoint_callback=False)
trainer.fit(model)
```

## Make Predictions

```{python}
# Predict and fill in submission template
for spec, id_, subject, ts in dataset.test_data_list:
    output = model([torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0),
                    torch.tensor(ts).type('torch.FloatTensor').view(ts.shape[0], -1)])
    prediction = output.argmax(dim=0, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

```{python}
 tst_sc1.subject_id.unique()
```

# Subject 1034 Model

```{python}
torch.cuda.empty_cache()
```

```{python}
subject_id = 1034
```

```{python}
dataset.run_preprocessing(specific_key_dataset=subject_id)
```

```{python}
dataset.run_test_preprocessing(specific_key_dataset=subject_id)
```

## Train Validation Split

```{python}
dataset.train_validation_split(val_proportion=0.2)
```

```{python}
print('Training size:',len(dataset.train_list))
print('Validation size:',len(dataset.val_list))
```

## Run Training/Validation

```{python}
# Hyperparameters
hparams = Namespace(**{'learning_rate':learning_rate, 'train_batch_size': train_batch_size,
                       'val_batch_size': val_batch_size})
```

```{python}
# Run training/validation of model
model = LightningEnsemble(dataset_name=dataset_name,hparams=hparams,train_list=dataset.train_list,
                       val_list=dataset.val_list,label_class=label_class)
logger = TensorBoardLogger("lightning_logs", name=model_name, version=f'subject_{subject_id}_{label_class}')
trainer = pl.Trainer(early_stop_callback=early_stop_callback,
                     max_epochs=max_epochs, gpus=gpus, logger=logger,checkpoint_callback=False)
trainer.fit(model)
```

## Make Predictions

```{python}
# Predict and fill in submission template
for spec, id_, subject, ts in dataset.test_data_list:
    output = model([torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0),
                    torch.tensor(ts).type('torch.FloatTensor').view(ts.shape[0], -1)])
    prediction = output.argmax(dim=0, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

```{python}
 tst_sc1.subject_id.unique()
```

# Subject 1038 Model

```{python}
torch.cuda.empty_cache()
```

```{python}
subject_id = 1038
```

```{python}
dataset.run_preprocessing(specific_key_dataset=subject_id)
```

```{python}
dataset.run_test_preprocessing(specific_key_dataset=subject_id)
```

## Train Validation Split

```{python}
dataset.train_validation_split(val_proportion=0.2)
```

```{python}
print('Training size:',len(dataset.train_list))
print('Validation size:',len(dataset.val_list))
```

## Run Training/Validation

```{python}
# Hyperparameters
hparams = Namespace(**{'learning_rate':learning_rate, 'train_batch_size': train_batch_size,
                       'val_batch_size': val_batch_size})
```

```{python}
# Run training/validation of model
model = LightningEnsemble(dataset_name=dataset_name,hparams=hparams,train_list=dataset.train_list,
                       val_list=dataset.val_list,label_class=label_class)
logger = TensorBoardLogger("lightning_logs", name=model_name, version=f'subject_{subject_id}_{label_class}')
trainer = pl.Trainer(early_stop_callback=early_stop_callback,
                     max_epochs=max_epochs, gpus=gpus, logger=logger,checkpoint_callback=False)
trainer.fit(model)
```

## Make Predictions

```{python}
# Predict and fill in submission template
for spec, id_, subject, ts in dataset.test_data_list:
    output = model([torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0),
                    torch.tensor(ts).type('torch.FloatTensor').view(ts.shape[0], -1)])
    prediction = output.argmax(dim=0, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

```{python}
 tst_sc1.subject_id.unique()
```

# Subject 1039 Model

```{python}
torch.cuda.empty_cache()
```

```{python}
subject_id = 1039
```

```{python}
dataset.run_preprocessing(specific_key_dataset=subject_id)
```

```{python}
dataset.run_test_preprocessing(specific_key_dataset=subject_id)
```

## Train Validation Split

```{python}
dataset.train_validation_split(val_proportion=0.2)
```

```{python}
print('Training size:',len(dataset.train_list))
print('Validation size:',len(dataset.val_list))
```

## Run Training/Validation

```{python}
# Hyperparameters
hparams = Namespace(**{'learning_rate':learning_rate, 'train_batch_size': train_batch_size,
                       'val_batch_size': val_batch_size})
```

```{python}
# Predict and fill in submission template
for spec, id_, subject, ts in dataset.test_data_list:
    output = model([torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0),
                    torch.tensor(ts).type('torch.FloatTensor').view(ts.shape[0], -1)])
    prediction = output.argmax(dim=0, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

## Make Predictions

```{python}
# Predict and fill in submission template
for spec, id_, subject in dataset.test_data_list:
    output = model(torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0))
    prediction = output.argmax(dim=1, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

```{python}
 tst_sc1.subject_id.unique()
```

# Subject 1043 Model

```{python}
torch.cuda.empty_cache()
```

```{python}
subject_id = 1043
```

```{python}
dataset.run_preprocessing(specific_key_dataset=subject_id)
```

```{python}
dataset.run_test_preprocessing(specific_key_dataset=subject_id)
```

## Train Validation Split

```{python}
dataset.train_validation_split(val_proportion=0.2)
```

```{python}
print('Training size:',len(dataset.train_list))
print('Validation size:',len(dataset.val_list))
```

## Run Training/Validation

```{python}
# Hyperparameters
hparams = Namespace(**{'learning_rate':learning_rate, 'train_batch_size': train_batch_size,
                       'val_batch_size': val_batch_size})
```

```{python}
# Run training/validation of model
model = LightningEnsemble(dataset_name=dataset_name,hparams=hparams,train_list=dataset.train_list,
                       val_list=dataset.val_list,label_class=label_class)
logger = TensorBoardLogger("lightning_logs", name=model_name, version=f'subject_{subject_id}_{label_class}')
trainer = pl.Trainer(early_stop_callback=early_stop_callback,
                     max_epochs=max_epochs, gpus=gpus, logger=logger,checkpoint_callback=False)
trainer.fit(model)
```

## Make Predictions

```{python}
# Predict and fill in submission template
for spec, id_, subject, ts in dataset.test_data_list:
    output = model([torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0),
                    torch.tensor(ts).type('torch.FloatTensor').view(ts.shape[0], -1)])
    prediction = output.argmax(dim=0, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

```{python}
 tst_sc1.subject_id.unique()
```

# Subject 1044 Model

```{python}
torch.cuda.empty_cache()
```

```{python}
subject_id = 1044
```

```{python}
dataset.run_preprocessing(specific_key_dataset=subject_id)
```

```{python}
dataset.run_test_preprocessing(specific_key_dataset=subject_id)
```

## Train Validation Split

```{python}
dataset.train_validation_split(val_proportion=0.2)
```

```{python}
print('Training size:',len(dataset.train_list))
print('Validation size:',len(dataset.val_list))
```

## Run Training/Validation

```{python}
# Hyperparameters
hparams = Namespace(**{'learning_rate':learning_rate, 'train_batch_size': train_batch_size,
                       'val_batch_size': val_batch_size})
```

```{python}
# Run training/validation of model
model = LightningEnsemble(dataset_name=dataset_name,hparams=hparams,train_list=dataset.train_list,
                       val_list=dataset.val_list,label_class=label_class)
logger = TensorBoardLogger("lightning_logs", name=model_name, version=f'subject_{subject_id}_{label_class}')
trainer = pl.Trainer(early_stop_callback=early_stop_callback,
                     max_epochs=max_epochs, gpus=gpus, logger=logger,checkpoint_callback=False)
trainer.fit(model)
```

## Make Predictions

```{python}
# Predict and fill in submission template
for spec, id_, subject, ts in dataset.test_data_list:
    output = model([torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0),
                    torch.tensor(ts).type('torch.FloatTensor').view(ts.shape[0], -1)])
    prediction = output.argmax(dim=0, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

```{python}
 tst_sc1.subject_id.unique()
```

# Subject 1048 Model

```{python}
torch.cuda.empty_cache()
```

```{python}
subject_id = 1048
```

```{python}
dataset.run_preprocessing(specific_key_dataset=subject_id)
```

```{python}
dataset.run_test_preprocessing(specific_key_dataset=subject_id)
```

## Train Validation Split

```{python}
dataset.train_validation_split(val_proportion=0.2)
```

```{python}
print('Training size:',len(dataset.train_list))
print('Validation size:',len(dataset.val_list))
```

## Run Training/Validation

```{python}
# Hyperparameters
hparams = Namespace(**{'learning_rate':learning_rate, 'train_batch_size': train_batch_size,
                       'val_batch_size': val_batch_size})
```

```{python}
# Run training/validation of model
model = LightningEnsemble(dataset_name=dataset_name,hparams=hparams,train_list=dataset.train_list,
                       val_list=dataset.val_list,label_class=label_class)
logger = TensorBoardLogger("lightning_logs", name=model_name, version=f'subject_{subject_id}_{label_class}')
trainer = pl.Trainer(early_stop_callback=early_stop_callback,
                     max_epochs=max_epochs, gpus=gpus, logger=logger,checkpoint_callback=False)
trainer.fit(model)
```

## Make Predictions

```{python}
# Predict and fill in submission template
for spec, id_, subject, ts in dataset.test_data_list:
    output = model([torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0),
                    torch.tensor(ts).type('torch.FloatTensor').view(ts.shape[0], -1)])
    prediction = output.argmax(dim=0, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

```{python}
 tst_sc1.subject_id.unique()
```

# Subject 1049 Model

```{python}
torch.cuda.empty_cache()
```

```{python}
subject_id = 1049
```

```{python}
dataset.run_preprocessing(specific_key_dataset=subject_id)
```

```{python}
dataset.run_test_preprocessing(specific_key_dataset=subject_id)
```

## Train Validation Split

```{python}
dataset.train_validation_split(val_proportion=0.2)
```

```{python}
print('Training size:',len(dataset.train_list))
print('Validation size:',len(dataset.val_list))
```

## Run Training/Validation

```{python}
# Hyperparameters
hparams = Namespace(**{'learning_rate':learning_rate, 'train_batch_size': train_batch_size,
                       'val_batch_size': val_batch_size})
```

```{python}
# Run training/validation of model
model = LightningEnsemble(dataset_name=dataset_name,hparams=hparams,train_list=dataset.train_list,
                       val_list=dataset.val_list,label_class=label_class)
logger = TensorBoardLogger("lightning_logs", name=model_name, version=f'subject_{subject_id}_{label_class}')
trainer = pl.Trainer(early_stop_callback=early_stop_callback,
                     max_epochs=max_epochs, gpus=gpus, logger=logger,checkpoint_callback=False)
trainer.fit(model)
```

## Make Predictions

```{python}
# Predict and fill in submission template
for spec, id_, subject, ts in dataset.test_data_list:
    output = model([torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0),
                    torch.tensor(ts).type('torch.FloatTensor').view(ts.shape[0], -1)])
    prediction = output.argmax(dim=0, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

```{python}
 tst_sc1.subject_id.unique()
```

# Subject 1051 Model

```{python}
torch.cuda.empty_cache()
```

```{python}
subject_id = 1051
```

```{python}
dataset.run_preprocessing(specific_key_dataset=subject_id)
```

```{python}
dataset.run_test_preprocessing(specific_key_dataset=subject_id)
```

## Train Validation Split

```{python}
dataset.train_validation_split(val_proportion=0.2)
```

```{python}
print('Training size:',len(dataset.train_list))
print('Validation size:',len(dataset.val_list))
```

## Run Training/Validation

```{python}
# Hyperparameters
hparams = Namespace(**{'learning_rate':learning_rate, 'train_batch_size': train_batch_size,
                       'val_batch_size': val_batch_size})
```

```{python}
# Run training/validation of model
model = LightningEnsemble(dataset_name=dataset_name,hparams=hparams,train_list=dataset.train_list,
                       val_list=dataset.val_list,label_class=label_class)
logger = TensorBoardLogger("lightning_logs", name=model_name, version=f'subject_{subject_id}_{label_class}')
trainer = pl.Trainer(early_stop_callback=early_stop_callback,
                     max_epochs=max_epochs, gpus=gpus, logger=logger,checkpoint_callback=False)
trainer.fit(model)
```

## Make Predictions

```{python}
# Predict and fill in submission template
for spec, id_, subject, ts in dataset.test_data_list:
    output = model([torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0),
                    torch.tensor(ts).type('torch.FloatTensor').view(ts.shape[0], -1)])
    prediction = output.argmax(dim=0, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

# Create REAL Dataset

```{python}
############### REAL config ###############

dataset_name = 'REAL'
label_class = 'on_off'
sort_by = 'subject_id'
train_ts_dir = 'Data/BEATPDchallenge/BeatPDRealPDupdated/real-pd.training_data_updated/training_data/'
train_label_dir = 'Data/BEATPDchallenge/data_labels-realpd/REAL-PD_Training_Data_IDs_Labels.csv'
ancil_ts_dir = 'Data/BEATPDchallenge/BeatPDRealPDupdated/real-pd.ancillary_data_updated/ancillary_data/'
ancil_label_dir = 'Data/BEATPDchallenge/data_labels-realpd/REAL-PD_Ancillary_Data_IDs_Labels.csv'
test_ts_dir='Data/BEATPDchallenge/BeatPDRealPDupdated/real-pd.testing_data_updated/testing_data/'
test_data_id_dir='Data/BEATPDchallenge/REAL-PD_Test_Data_IDs.csv'
```

```{python}
REALdataset = Dataset(dataset_name=dataset_name, sort_by=sort_by, label_class = label_class,
                           train_ts_dir=train_ts_dir, train_label_dir=train_label_dir,
                           ancil_ts_dir=ancil_ts_dir, ancil_label_dir=ancil_label_dir,
                           combine_ancil=False,test_ts_dir=test_ts_dir, test_data_id_dir=test_data_id_dir)
```

```{python}
REALdataset.data_dict.keys()
```

```{python}
REALdataset.test_data_dict.keys()
```

```{python}
tst_sc1.subject_id.unique()
```

# Subject hbv013 Model

```{python}
torch.cuda.empty_cache()
```

```{python}
subject_id = 'hbv013'
```

```{python}
REALdataset.run_preprocessing(specific_key_dataset=subject_id)
```

```{python}
REALdataset.run_test_preprocessing(specific_key_dataset=subject_id)
```

## Train Validation Split

```{python}
REALdataset.train_validation_split(val_proportion=0.2)
```

```{python}
print('Training size:',len(REALdataset.train_list))
print('Validation size:',len(REALdataset.val_list))
```

## Run Training/Validation

```{python}
# Hyperparameters
hparams = Namespace(**{'learning_rate':learning_rate, 'train_batch_size': train_batch_size,
                       'val_batch_size': val_batch_size})
```

```{python}
# Run training/validation of model
model = LightningEnsemble(dataset_name=dataset_name,hparams=hparams,train_list=dataset.train_list,
                       val_list=dataset.val_list,label_class=label_class)
logger = TensorBoardLogger("lightning_logs", name=model_name, version=f'subject_{subject_id}_{label_class}')
trainer = pl.Trainer(early_stop_callback=early_stop_callback,
                     max_epochs=max_epochs, gpus=gpus, logger=logger,checkpoint_callback=False)
trainer.fit(model)
```

## Make Predictions

```{python}
# Predict and fill in submission template
for spec, id_, subject, ts in dataset.test_data_list:
    output = model([torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0),
                    torch.tensor(ts).type('torch.FloatTensor').view(ts.shape[0], -1)])
    prediction = output.argmax(dim=0, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

```{python}
tst_sc1.subject_id.unique()
```

# Subject hbv038 Model

```{python}
subject_id = 'hbv038'
```

```{python}
REALdataset.run_preprocessing(specific_key_dataset=subject_id)
```

```{python}
REALdataset.run_test_preprocessing(specific_key_dataset=subject_id)
```

## Train Validation Split

```{python}
REALdataset.train_validation_split(val_proportion=0.2)
```

```{python}
print('Training size:',len(REALdataset.train_list))
print('Validation size:',len(REALdataset.val_list))
```

## Run Training/Validation

```{python}
# Hyperparameters
hparams = Namespace(**{'learning_rate':learning_rate, 'train_batch_size': train_batch_size,
                       'val_batch_size': val_batch_size})
```

```{python}
# Run training/validation of model
model = LightningEnsemble(dataset_name=dataset_name,hparams=hparams,train_list=dataset.train_list,
                       val_list=dataset.val_list,label_class=label_class)
logger = TensorBoardLogger("lightning_logs", name=model_name, version=f'subject_{subject_id}_{label_class}')
trainer = pl.Trainer(early_stop_callback=early_stop_callback,
                     max_epochs=max_epochs, gpus=gpus, logger=logger,checkpoint_callback=False)
trainer.fit(model)
```

## Make Predictions

```{python}
# Predict and fill in submission template
for spec, id_, subject, ts in dataset.test_data_list:
    output = model([torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0),
                    torch.tensor(ts).type('torch.FloatTensor').view(ts.shape[0], -1)])
    prediction = output.argmax(dim=0, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

```{python}
tst_sc1.subject_id.unique()
```

# Subject hbv051 Model

```{python}
torch.cuda.empty_cache()
```

```{python}
subject_id = 'hbv051'
```

```{python}
REALdataset.run_preprocessing(specific_key_dataset=subject_id)
```

```{python}
REALdataset.run_test_preprocessing(specific_key_dataset=subject_id)
```

## Train Validation Split

```{python}
REALdataset.train_validation_split(val_proportion=0.2)
```

```{python}
print('Training size:',len(REALdataset.train_list))
print('Validation size:',len(REALdataset.val_list))
```

## Run Training/Validation

```{python}
# Hyperparameters
hparams = Namespace(**{'learning_rate':learning_rate, 'train_batch_size': train_batch_size,
                       'val_batch_size': val_batch_size})
```

```{python}
# Run training/validation of model
model = LightningEnsemble(dataset_name=dataset_name,hparams=hparams,train_list=dataset.train_list,
                       val_list=dataset.val_list,label_class=label_class)
logger = TensorBoardLogger("lightning_logs", name=model_name, version=f'subject_{subject_id}_{label_class}')
trainer = pl.Trainer(early_stop_callback=early_stop_callback,
                     max_epochs=max_epochs, gpus=gpus, logger=logger,checkpoint_callback=False)
trainer.fit(model)
```

## Make Predictions

```{python}
# Predict and fill in submission template
for spec, id_, subject, ts in dataset.test_data_list:
    output = model([torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0),
                    torch.tensor(ts).type('torch.FloatTensor').view(ts.shape[0], -1)])
    prediction = output.argmax(dim=0, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

```{python}
tst_sc1.subject_id.unique()
```

# Subject hbv077 Model

```{python}
torch.cuda.empty_cache()
```

```{python}
subject_id = 'hbv077'
```

```{python}
REALdataset.run_preprocessing(specific_key_dataset=subject_id)
```

```{python}
REALdataset.run_test_preprocessing(specific_key_dataset=subject_id)
```

## Train Validation Split

```{python}
REALdataset.train_validation_split(val_proportion=0.2)
```

```{python}
print('Training size:',len(REALdataset.train_list))
print('Validation size:',len(REALdataset.val_list))
```

## Run Training/Validation

```{python}
# Hyperparameters
hparams = Namespace(**{'learning_rate':learning_rate, 'train_batch_size': train_batch_size,
                       'val_batch_size': val_batch_size})
```

```{python}
# Run training/validation of model
model = LightningEnsemble(dataset_name=dataset_name,hparams=hparams,train_list=dataset.train_list,
                       val_list=dataset.val_list,label_class=label_class)
logger = TensorBoardLogger("lightning_logs", name=model_name, version=f'subject_{subject_id}_{label_class}')
trainer = pl.Trainer(early_stop_callback=early_stop_callback,
                     max_epochs=max_epochs, gpus=gpus, logger=logger,checkpoint_callback=False)
trainer.fit(model)
```

## Make Predictions

```{python}
# Predict and fill in submission template
for spec, id_, subject, ts in dataset.test_data_list:
    output = model([torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0),
                    torch.tensor(ts).type('torch.FloatTensor').view(ts.shape[0], -1)])
    prediction = output.argmax(dim=0, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

```{python}
tst_sc1.subject_id.unique()
```

# Subject hbv014 Model

```{python}
torch.cuda.empty_cache()
```

```{python}
subject_id = 'hbv014'
```

```{python}
REALdataset.run_preprocessing(specific_key_dataset=subject_id)
```

```{python}
REALdataset.run_test_preprocessing(specific_key_dataset=subject_id)
```

## Train Validation Split

```{python}
REALdataset.train_validation_split(val_proportion=0.2)
```

```{python}
print('Training size:',len(REALdataset.train_list))
print('Validation size:',len(REALdataset.val_list))
```

## Run Training/Validation

```{python}
# Hyperparameters
hparams = Namespace(**{'learning_rate':learning_rate, 'train_batch_size': train_batch_size,
                       'val_batch_size': val_batch_size})
```

```{python}
# Run training/validation of model
model = LightningEnsemble(dataset_name=dataset_name,hparams=hparams,train_list=dataset.train_list,
                       val_list=dataset.val_list,label_class=label_class)
logger = TensorBoardLogger("lightning_logs", name=model_name, version=f'subject_{subject_id}_{label_class}')
trainer = pl.Trainer(early_stop_callback=early_stop_callback,
                     max_epochs=max_epochs, gpus=gpus, logger=logger,checkpoint_callback=False)
trainer.fit(model)
```

## Make Predictions

```{python}
# Predict and fill in submission template
for spec, id_, subject, ts in dataset.test_data_list:
    output = model([torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0),
                    torch.tensor(ts).type('torch.FloatTensor').view(ts.shape[0], -1)])
    prediction = output.argmax(dim=0, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

```{python}
tst_sc1.subject_id.unique()
```

# Subject hbv043 Model

```{python}
torch.cuda.empty_cache()
```

```{python}
subject_id = 'hbv043'
```

```{python}
REALdataset.run_preprocessing(specific_key_dataset=subject_id)
```

```{python}
REALdataset.run_test_preprocessing(specific_key_dataset=subject_id)
```

## Train Validation Split

```{python}
REALdataset.train_validation_split(val_proportion=0.2)
```

```{python}
print('Training size:',len(REALdataset.train_list))
print('Validation size:',len(REALdataset.val_list))
```

## Run Training/Validation

```{python}
# Hyperparameters
hparams = Namespace(**{'learning_rate':learning_rate, 'train_batch_size': train_batch_size,
                       'val_batch_size': val_batch_size})
```

```{python}
# Run training/validation of model
model = LightningEnsemble(dataset_name=dataset_name,hparams=hparams,train_list=dataset.train_list,
                       val_list=dataset.val_list,label_class=label_class)
logger = TensorBoardLogger("lightning_logs", name=model_name, version=f'subject_{subject_id}_{label_class}')
trainer = pl.Trainer(early_stop_callback=early_stop_callback,
                     max_epochs=max_epochs, gpus=gpus, logger=logger,checkpoint_callback=False)
trainer.fit(model)
```

## Make Predictions

```{python}
# Predict and fill in submission template
for spec, id_, subject, ts in dataset.test_data_list:
    output = model([torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0),
                    torch.tensor(ts).type('torch.FloatTensor').view(ts.shape[0], -1)])
    prediction = output.argmax(dim=0, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

```{python}
tst_sc1.subject_id.unique()
```

# Subject hbv022 Model

```{python}
torch.cuda.empty_cache()
```

```{python}
subject_id = 'hbv022'
```

```{python}
REALdataset.run_preprocessing(specific_key_dataset=subject_id)
```

```{python}
REALdataset.run_test_preprocessing(specific_key_dataset=subject_id)
```

## Train Validation Split

```{python}
REALdataset.train_validation_split(val_proportion=0.2)
```

```{python}
print('Training size:',len(REALdataset.train_list))
print('Validation size:',len(REALdataset.val_list))
```

## Run Training/Validation

```{python}
# Hyperparameters
hparams = Namespace(**{'learning_rate':learning_rate, 'train_batch_size': train_batch_size,
                       'val_batch_size': val_batch_size})
```

```{python}
# Run training/validation of model
model = LightningEnsemble(dataset_name=dataset_name,hparams=hparams,train_list=dataset.train_list,
                       val_list=dataset.val_list,label_class=label_class)
logger = TensorBoardLogger("lightning_logs", name=model_name, version=f'subject_{subject_id}_{label_class}')
trainer = pl.Trainer(early_stop_callback=early_stop_callback,
                     max_epochs=max_epochs, gpus=gpus, logger=logger,checkpoint_callback=False)
trainer.fit(model)
```

## Make Predictions

```{python}
# Predict and fill in submission template
for spec, id_, subject, ts in dataset.test_data_list:
    output = model([torch.unsqueeze(TF.to_tensor(spec).cuda(), dim=0),
                    torch.tensor(ts).type('torch.FloatTensor').view(ts.shape[0], -1)])
    prediction = output.argmax(dim=0, keepdim=True).item()
    df_index = tst_sc1.index[tst_sc1['measurement_id'] == id_]
    tst_sc1.prediction[df_index] = prediction
```

# Save Predictions

```{python}
del tst_sc1['subject_id']
```

```{python}
tst_sc1.prediction = tst_sc1.prediction.astype(int)
```

```{python}
#Save submission df to CSV
#tst_sc1.to_csv('Data/on_off_submission2.csv', index=False)
```

```{python}
# Check to see if csv saved correctly
#pd.read_csv('Data/on_off_submission2.csv').head()
```
